{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ6SNYq_tVVC"
   },
   "source": [
    "# Classify text with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCjmX4zTCkRK"
   },
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5w_XlxN1IsRJ"
   },
   "source": [
    "We use the AdamW optimizer from [tensorflow/models](https://github.com/tensorflow/models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "b-P1ZOA0FkVJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.python.org/simple/\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch) (4.1.1)\n",
      "Looking in indexes: https://pypi.python.org/simple/\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.18.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2022.4.24)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.22.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (8.0.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "# First install all necessary packages\n",
    "\n",
    "!pip install torch\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "_XgTpm9ZxoN9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "from utils import load_data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics, model_selection, preprocessing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import transformers\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/jovyan/workbench-shared-folder/workbench-shared-folder/canary-project/Paula_internship/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vnvd4mrtPHHV"
   },
   "source": [
    "### Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "pOdqCMoQDRJL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  4.83 Mb (83.6% reduction)\n",
      "Mem. usage decreased to  2.42 Mb (83.6% reduction)\n",
      "Mem. usage decreased to  0.81 Mb (83.6% reduction)\n",
      "Set A with suffix '_kw' was loaded successfully.\n",
      "Mem. usage decreased to  5.18 Mb (83.6% reduction)\n",
      "Mem. usage decreased to  2.59 Mb (83.6% reduction)\n",
      "Mem. usage decreased to  0.86 Mb (83.6% reduction)\n",
      "Set B with suffix '_kw' was loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/workbench-shared-folder/canary-project/Paula_internship/utils.py:46: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  train = pd.read_csv(f\"{path}set_{version}_train{suffix}.csv\", engine='python', error_bad_lines=False)\n",
      "Skipping line 157634: unexpected end of data\n",
      "/home/jovyan/workbench-shared-folder/canary-project/Paula_internship/utils.py:47: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  test = pd.read_csv(f\"{path}set_{version}_test{suffix}.csv\", engine='python', error_bad_lines=False)\n",
      "/home/jovyan/workbench-shared-folder/canary-project/Paula_internship/utils.py:48: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  val = pd.read_csv(f\"{path}set_{version}_val{suffix}.csv\", engine='python', error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 10.82 Mb (83.6% reduction)\n",
      "Mem. usage decreased to  5.42 Mb (83.6% reduction)\n",
      "Mem. usage decreased to  1.81 Mb (83.6% reduction)\n",
      "Set EX with suffix '_kw' was loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# DATA_PATH = \"../data/\"\n",
    "DATA_PATH = \"/home/jovyan/workbench-shared-folder/canary-project/Paula_internship/data/\"\n",
    "\n",
    "# Load data from Set A, B and EX\n",
    "train_A, test_A, val_A = load_data(DATA_PATH, version=\"A\", suffix=\"_kw\", reduce_memory=True)\n",
    "train_B, test_B, val_B = load_data(DATA_PATH, version=\"B\", suffix=\"_kw\", reduce_memory=True)\n",
    "train_EX, test_EX, val_EX = load_data(DATA_PATH, version=\"EX\", suffix=\"_kw\", reduce_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We concatenate the 3 different sets (A, B, EX):\n",
    "\n",
    "train = pd.concat([train_A, train_B, train_EX])\n",
    "test = pd.concat([test_A, test_B, test_EX])\n",
    "val = pd.concat([val_A, val_B, val_EX])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Classifier using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define useful classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    '''\n",
    "    Dataset class to map indices/keys of data samples. Implemented __getitem__() and __len__() protocols.\n",
    "    Using the tokenizer, the inputs are mapped to BERT ids/mask.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_len, truncate):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.truncation = truncate\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        inputs = self.tokenizer.__call__(text,\n",
    "                                        None,\n",
    "                                        add_special_tokens=True,\n",
    "                                        max_length=self.max_len,\n",
    "                                        padding=\"max_length\",\n",
    "                                        truncation=self.truncation,\n",
    "                                        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        return {\n",
    "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
    "            \"mask\": torch.tensor(mask, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    '''\n",
    "    The actual NN used for classification\n",
    "    '''\n",
    "    def __init__(self, n_train_steps, n_classes, do_prob, bert_model):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout = nn.Dropout(do_prob)\n",
    "        self.out = nn.Linear(768, n_classes)\n",
    "        self.n_train_steps = n_train_steps\n",
    "        self.step_scheduler_after = \"batch\"\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        output_1 = self.bert(ids, attention_mask=mask)[\"pooler_output\"]\n",
    "        output_2 = self.dropout(output_1)\n",
    "        output = self.out(output_2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = train.iloc[:, 3:].shape[1]\n",
    "tokenizer = transformers.SqueezeBertTokenizer.from_pretrained(\"squeezebert/squeezebert-uncased\", do_lower_case=True)\n",
    "\n",
    "def build_dataset(tokenizer_max_len, truncate):\n",
    "    '''\n",
    "    Tokenize and map the training and validation sets\n",
    "    '''\n",
    "    train_dataset = Dataset(train.input.tolist(), train.iloc[:, 3:].values.tolist(), tokenizer, tokenizer_max_len, truncate)\n",
    "    valid_dataset = Dataset(val.input.tolist(), val.iloc[:, 3:].values.tolist(), tokenizer, tokenizer_max_len, truncate)\n",
    "    \n",
    "    return train_dataset, valid_dataset\n",
    "\n",
    "def build_dataloader(train_dataset, valid_dataset, batch_size):\n",
    "    '''\n",
    "    Create the torch dataloaders\n",
    "    '''\n",
    "    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    valid_data_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "    return train_data_loader, valid_data_loader\n",
    "\n",
    "def ret_model(n_train_steps, do_prob):\n",
    "    '''\n",
    "    Retrieve the model\n",
    "    '''\n",
    "    model = Classifier(n_train_steps, n_labels, do_prob, bert_model=bert_model)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at squeezebert/squeezebert-uncased were not used when initializing SqueezeBertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing SqueezeBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SqueezeBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_model = transformers.SqueezeBertModel.from_pretrained(\"squeezebert/squeezebert-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_optimizer(model):\n",
    "    '''\n",
    "    Taken from Abhishek Thakur's Tez library example: \n",
    "    https://github.com/abhishekkrthakur/tez/blob/main/examples/text_classification/binary.py\n",
    "    '''\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\"]\n",
    "    optimizer_parameters = [\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": 0.001,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "#     opt = AdamW(optimizer_parameters, lr=config['learning_rate'])\n",
    "    opt = torch.optim.AdamW(optimizer_parameters, lr=config['learning_rate'])\n",
    "    return opt\n",
    "\n",
    "def ret_scheduler(optimizer, num_train_steps):\n",
    "    sch = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=0, num_training_steps=num_train_steps)\n",
    "    return sch\n",
    "\n",
    "def loss_function(outputs, labels, loss='BCE'):\n",
    "    if labels is None:\n",
    "        return None\n",
    "    if loss == 'BCE':\n",
    "        # BinaryCross Entropy loss\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "    else:\n",
    "        # BinaryCross Entropy loss\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    return loss_fn(outputs, labels.float())\n",
    "\n",
    "def log_metrics(preds, labels):\n",
    "    preds = torch.stack(preds)\n",
    "    preds = preds.cpu().detach().numpy()\n",
    "    labels = torch.stack(labels)\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "    \n",
    "    '''\n",
    "    auc_micro_list = []\n",
    "    for i in range(n_labels):\n",
    "      current_pred = preds.T[i]\n",
    "      current_label = labels.T[i]\n",
    "      fpr_micro, tpr_micro, _ = metrics.roc_curve(current_label.T, current_pred.T)\n",
    "      auc_micro = metrics.auc(fpr_micro, tpr_micro)\n",
    "      auc_micro_list.append(auc_micro)\n",
    "    \n",
    "    return {\"auc\": np.array(auc_micro).mean()}\n",
    "    '''\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve\n",
    "    fpr_micro, tpr_micro, _ = metrics.roc_curve(labels.ravel(), preds.ravel())\n",
    "    \n",
    "    auc_micro = metrics.auc(fpr_micro, tpr_micro)\n",
    "    return {\"auc_micro\": auc_micro}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_fn(data_loader, model, loss_fn, optimizer, device, scheduler):\n",
    "    '''\n",
    "        Modified from Abhishek Thakur's BERT example: \n",
    "        https://github.com/abhishekkrthakur/bert-sentiment/blob/master/src/engine.py\n",
    "    '''\n",
    "\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        ids = d[\"ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        targets = d[\"labels\"]\n",
    "\n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(ids=ids, mask=mask)\n",
    "\n",
    "        loss = loss_function(outputs, targets, loss_fn)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    return train_loss\n",
    "    \n",
    "\n",
    "def eval_fn(data_loader, model, device):\n",
    "    '''\n",
    "        Modified from Abhishek Thakur's BERT example: \n",
    "        https://github.com/abhishekkrthakur/bert-sentiment/blob/master/src/engine.py\n",
    "    '''\n",
    "    eval_loss = 0.0\n",
    "    model.eval()\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            ids = d[\"ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            targets = d[\"labels\"]\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(ids=ids, mask=mask)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            eval_loss += loss.item()\n",
    "            fin_targets.extend(targets)\n",
    "            fin_outputs.extend(torch.sigmoid(outputs))\n",
    "    return eval_loss, fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(config):\n",
    "\n",
    "    train_dataset, valid_dataset = build_dataset(config['tokenizer_max_len'], config['truncate'])\n",
    "    train_data_loader, valid_data_loader = build_dataloader(train_dataset, valid_dataset, config['batch_size'])\n",
    "    print(\"Length of Train Dataloader: \", len(train_data_loader))\n",
    "    print(\"Length of Valid Dataloader: \", len(valid_data_loader))\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    n_train_steps = int(len(train_dataset) / config['batch_size'] * 10)\n",
    "\n",
    "    model = ret_model(n_train_steps, config['dropout'])\n",
    "    optimizer = ret_optimizer(model)\n",
    "    scheduler = ret_scheduler(optimizer, n_train_steps)\n",
    "    model.to(device)\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "    n_epochs = config['epochs']\n",
    "    loss_fn = config['loss']\n",
    "\n",
    "    best_val_loss = 100\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        print('Train EPOCH: ', epoch)\n",
    "        train_loss = train_fn(train_data_loader, model, loss_fn, optimizer, device, scheduler)\n",
    "        eval_loss, preds, labels = eval_fn(valid_data_loader, model, device)\n",
    "        \n",
    "        metrics_eval = log_metrics(preds, labels)\n",
    "        try:\n",
    "            auc_score  = metrics_eval[\"auc_micro\"]\n",
    "#             print(\"AUC score: \", auc_score)\n",
    "        except:\n",
    "            pass\n",
    "        avg_train_loss, avg_val_loss = train_loss / len(train_data_loader), eval_loss / len(valid_data_loader)\n",
    "\n",
    "        print(\"Average Train loss: \", avg_train_loss)\n",
    "        print(\"Average Valid loss: \", avg_val_loss)\n",
    "        torch.save(model.state_dict(), \"./model_current.pt\")  \n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), \"./model_best.pt\")  \n",
    "            print(\"Model saved as current val_loss is: \", best_val_loss)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some configuration parameters (to be fine-tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'learning_rate': 1e-3,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 10,\n",
    "    'dropout': 0.3,\n",
    "    'tokenizer_max_len': 200,\n",
    "    'truncate': True,\n",
    "    'loss': 'BCE',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train Dataloader:  9486\n",
      "Length of Valid Dataloader:  1583\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfd1ff35a45420ca8fd042b78977c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train EPOCH:  0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5622d368d65c4dc79435f500f2cb0aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model:\n",
    "\n",
    "trainer(config) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some functions for the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    '''\n",
    "    Load a saved model\n",
    "    '''\n",
    "    train_dataset, valid_dataset = build_dataset(config['tokenizer_max_len'], config['truncate'])\n",
    "    train_data_loader, valid_data_loader = build_dataloader(train_dataset, valid_dataset, config['batch_size'])\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    n_train_steps = int(len(train_dataset) / config['batch_size'] * 10)\n",
    "\n",
    "    model = ret_model(n_train_steps, config['dropout'])\n",
    "    optimizer = ret_optimizer(model)\n",
    "    scheduler = ret_scheduler(optimizer, n_train_steps)\n",
    "    model.to(device)\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "    Models_PATH = \"/home/jovyan/workbench-shared-folder/canary-project/Paula_internship/\"\n",
    "    model.load_state_dict(torch.load(Models_PATH + \"model_best.pt\", map_location=device))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_batches(test, model):\n",
    "    '''\n",
    "    Predict outputs for inference phase\n",
    "    '''\n",
    "    test_targets = []\n",
    "    test_outputs = []\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    test_dataset = Dataset(test.input.tolist(), test.iloc[:, 3:].values.tolist(), tokenizer, config['tokenizer_max_len'], config['truncate'])\n",
    "    data_loader = DataLoader(test_dataset, batch_size=1024, shuffle=True, num_workers=2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            ids = d[\"ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            labels = d[\"labels\"]\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(ids=ids, mask=mask)\n",
    "            test_targets.extend(labels.cpu().numpy())\n",
    "            test_outputs.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "\n",
    "\n",
    "    return test_outputs, test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates():\n",
    "    '''\n",
    "    Remove duplicates of train/val datasets present in the test set\n",
    "    '''\n",
    "    # Get the training duplicates:\n",
    "    duplicates_train = set(test.pui) & set(train.pui) \n",
    "    test_clean = test[~test['pui'].isin(duplicates_train)]\n",
    "    \n",
    "    # Get the validation duplicates:\n",
    "    duplicates_val = set(test.pui) & set(val.pui) \n",
    "    test_clean = test_clean[~test_clean['pui'].isin(duplicates_val)]\n",
    "    \n",
    "    assert test_clean.shape[0] == test.shape[0] - len(duplicates_train) - len(duplicates_val)\n",
    "    \n",
    "    return test_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(preds, labels):\n",
    "    '''\n",
    "    Create some metrics: precison, recall, F1...\n",
    "    '''\n",
    "    # Convert the lists to dataframes\n",
    "    lab_df = pd.DataFrame(labels)\n",
    "    pred_df = pd.DataFrame(preds).round(0).astype(int)\n",
    "    \n",
    "    # Calculate tp/fp/fn/tn per class:\n",
    "    tp = (pred_df + lab_df).eq(2).sum()\n",
    "    fp = (pred_df - lab_df).eq(1).sum()\n",
    "    fn = (pred_df - lab_df).eq(-1).sum()\n",
    "    tn = (pred_df + lab_df).eq(0).sum()\n",
    "    \n",
    "    # Calculate precision and recall:\n",
    "    prec = [tp[i] / (tp[i] + fp[i]) * 100.0 if tp[i] + fp[i] != 0 else 0.0 for i in range(len(tp))]\n",
    "    rec = [tp[i] / (tp[i] + fn[i]) * 100.0 if tp[i] + fn[i] != 0 else 0.0 for i in range(len(tp))]\n",
    "    \n",
    "    # Calculate F1 score:\n",
    "    f1_score = [2 * prec[i] * rec[i] / (prec[i] + rec[i]) if tp[i] > 0 else 0.0 for i in range(len(tp))]\n",
    "    \n",
    "    # Weighted F1 score:\n",
    "    weight = lab_df.sum() / sum(lab_df.sum())\n",
    "    f1_wght = [weight[i] * 2 * prec[i] * rec[i] / (prec[i] + rec[i]) if tp[i] > 0 else 0.0 for i in range(len(tp))]\n",
    "    \n",
    "    # Macro average:\n",
    "    prec_avg = sum(prec) / len(prec)\n",
    "    rec_avg = sum(rec) / len(rec)\n",
    "    f1_avg = sum(f1_score) / len(f1_score)\n",
    "    f1wgt_avg = sum(f1_wght) / len(f1_wght)\n",
    "    \n",
    "    return {\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1 score': f1_score,\n",
    "        'Weighted F1 score': f1_wght,\n",
    "        'Average precision': prec_avg.round(2),\n",
    "        'Average recall': rec_avg.round(2),\n",
    "        'Average F1 score': f1_avg.round(2),\n",
    "        'Average weighted F1 score': f1wgt_avg.round(2),\n",
    "    }\n",
    "\n",
    "# all_metrics = get_metrics(preds, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b2f7efee1c4cec8ba6bdaed1f8c079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict outputs:\n",
    "test_clean = remove_duplicates()\n",
    "model = load_model()\n",
    "preds, labels = inference_batches(test_clean, model)\n",
    "all_metrics = get_metrics(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision 5.89\n",
      "Average recall 9.62\n",
      "Average F1 score 7.27\n",
      "Average weighted F1 score 0.71\n"
     ]
    }
   ],
   "source": [
    "all_metrics = get_metrics(preds, labels)\n",
    "\n",
    "for metr, val in all_metrics.items():\n",
    "    if 'Average' in metr:\n",
    "        print(metr, val)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "classify_text_with_bert.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
