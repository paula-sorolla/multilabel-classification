{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZ6SNYq_tVVC"
   },
   "source": [
    "# Classify text with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCjmX4zTCkRK"
   },
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5w_XlxN1IsRJ"
   },
   "source": [
    "We use the AdamW optimizer from [tensorflow/models](https://github.com/tensorflow/models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "b-P1ZOA0FkVJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.python.org/simple/\n",
      "Collecting torch\n",
      "  Using cached torch-1.11.0-cp38-cp38-manylinux1_x86_64.whl (750.6 MB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch) (4.1.1)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.11.0\n",
      "Looking in indexes: https://pypi.python.org/simple/\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.27.1)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.7.0-py3-none-any.whl (10 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached tokenizers-0.12.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.4.24-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\n",
      "Collecting numpy>=1.17\n",
      "  Using cached numpy-1.22.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.6.0-py3-none-any.whl (84 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Installing collected packages: tokenizers, regex, numpy, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.7.0 huggingface-hub-0.6.0 numpy-1.22.4 regex-2022.4.24 tokenizers-0.12.1 transformers-4.19.2\n"
     ]
    }
   ],
   "source": [
    "# First install all necessary packages\n",
    "\n",
    "!pip install torch\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.python.org/simple/\n",
      "Collecting pandas\n",
      "  Using cached pandas-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/conda/lib/python3.8/site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.4.2 pytz-2022.1\n",
      "Looking in indexes: https://pypi.python.org/simple/\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-9.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (1.22.4)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pillow, kiwisolver, fonttools, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 fonttools-4.33.3 kiwisolver-1.4.2 matplotlib-3.5.2 pillow-9.1.1\n",
      "Looking in indexes: https://pypi.python.org/simple/\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0-py2.py3-none-any.whl\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.22.4)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting scipy>=1.3.2\n",
      "  Using cached scipy-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-1.1.0 scikit-learn-1.1.1 scipy-1.8.1 sklearn-0.0 threadpoolctl-3.1.0\n",
      "Looking in indexes: https://pypi.python.org/simple/\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement official (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for official\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install sklearn\n",
    "!pip install official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_XgTpm9ZxoN9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "from utils import load_data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics, model_selection, preprocessing\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import transformers\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "# from official.nlp import optimization  # to create AdamW optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/jovyan/workbench-shared-folder/workbench-shared-folder/canary-project/Paula_internship/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vnvd4mrtPHHV"
   },
   "source": [
    "### Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pOdqCMoQDRJL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  4.83 Mb (83.6% reduction)\n",
      "Mem. usage decreased to  2.42 Mb (83.6% reduction)\n",
      "Mem. usage decreased to  0.81 Mb (83.6% reduction)\n",
      "Set A with suffix '_kw' was loaded successfully.\n",
      "Mem. usage decreased to  5.18 Mb (83.6% reduction)\n",
      "Mem. usage decreased to  2.59 Mb (83.6% reduction)\n",
      "Mem. usage decreased to  0.86 Mb (83.6% reduction)\n",
      "Set B with suffix '_kw' was loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/workbench-shared-folder/canary-project/Paula_internship/utils.py:46: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  train = pd.read_csv(f\"{path}set_{version}_train{suffix}.csv\", engine='python', error_bad_lines=False)\n",
      "Skipping line 157634: unexpected end of data\n",
      "/home/jovyan/workbench-shared-folder/canary-project/Paula_internship/utils.py:47: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  test = pd.read_csv(f\"{path}set_{version}_test{suffix}.csv\", engine='python', error_bad_lines=False)\n",
      "/home/jovyan/workbench-shared-folder/canary-project/Paula_internship/utils.py:48: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  val = pd.read_csv(f\"{path}set_{version}_val{suffix}.csv\", engine='python', error_bad_lines=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 10.82 Mb (83.6% reduction)\n",
      "Mem. usage decreased to  5.42 Mb (83.6% reduction)\n",
      "Mem. usage decreased to  1.81 Mb (83.6% reduction)\n",
      "Set EX with suffix '_kw' was loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# DATA_PATH = \"../data/\"\n",
    "DATA_PATH = \"/home/jovyan/workbench-shared-folder/canary-project/Paula_internship/data/\"\n",
    "\n",
    "# Load data from Set A, B and EX\n",
    "train_A, test_A, val_A = load_data(DATA_PATH, version=\"A\", suffix=\"_kw\", reduce_memory=True)\n",
    "train_B, test_B, val_B = load_data(DATA_PATH, version=\"B\", suffix=\"_kw\", reduce_memory=True)\n",
    "train_EX, test_EX, val_EX = load_data(DATA_PATH, version=\"EX\", suffix=\"_kw\", reduce_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We concatenate the 3 different sets (A, B, EX):\n",
    "\n",
    "train = pd.concat([train_A, train_B, train_EX])\n",
    "test = pd.concat([test_A, test_B, test_EX])\n",
    "val = pd.concat([val_A, val_B, val_EX])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Classifier using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define useful classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    '''\n",
    "    Dataset class to map indices/keys of data samples. Implemented __getitem__() and __len__() protocols.\n",
    "    Using the tokenizer, the inputs are mapped to BERT ids/mask.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_len, truncate):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.truncation = truncate\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        inputs = self.tokenizer.__call__(text,\n",
    "                                        None,\n",
    "                                        add_special_tokens=True,\n",
    "                                        max_length=self.max_len,\n",
    "                                        padding=\"max_length\",\n",
    "                                        truncation=self.truncation,\n",
    "                                        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        return {\n",
    "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
    "            \"mask\": torch.tensor(mask, dtype=torch.long),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    '''\n",
    "    The actual NN used for classification\n",
    "    '''\n",
    "    def __init__(self, n_train_steps, n_classes, do_prob, bert_model):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dropout = nn.Dropout(do_prob)\n",
    "        self.out1 = nn.Linear(768, 256)\n",
    "        self.out2 = nn.Linear(256, n_classes)\n",
    "        self.n_train_steps = n_train_steps\n",
    "        self.step_scheduler_after = \"batch\"\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        output_1 = self.bert(ids, attention_mask=mask)[\"pooler_output\"]\n",
    "        output_2 = self.dropout(output_1)\n",
    "        output_3 = F.relu(self.out1(output_2))\n",
    "        output = F.softmax(self.out2(output_3))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define which BERT we are using:\n",
    "\n",
    "# # SPECTER: Document-level Representation Learning using Citation-informed Transformers\n",
    "# tokenizer = transformers.AutoTokenizer.from_pretrained(\"allenai/specter\", do_lower_case=True)\n",
    "# bert_model = transformers.AutoModel.from_pretrained(\"allenai/specter\")\n",
    "\n",
    "# # SCIBERT: BERT model trained on scientific text.\n",
    "# tokenizer = transformers.AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased', do_lower_case=True)\n",
    "# bert_model = transformers.AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "\n",
    "\n",
    "# # SQUEEZE BERT: \n",
    "# tokenizer = transformers.SqueezeBertTokenizer.from_pretrained(\"squeezebert/squeezebert-uncased\", do_lower_case=True)\n",
    "# bert_model = transformers.SqueezeBertModel.from_pretrained(\"squeezebert/squeezebert-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# FREEZE BERT PARAMS OR FINE-TUNE?\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased', do_lower_case=True)\n",
    "bert_model = transformers.AutoModel.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "\n",
    "for param in bert_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = train.iloc[:, 3:].shape[1]\n",
    "\n",
    "def build_dataset(tokenizer_max_len, truncate):\n",
    "    '''\n",
    "    Tokenize and map the training and validation sets\n",
    "    '''\n",
    "    train_dataset = Dataset(train.input.tolist(), train.iloc[:, 3:].values.tolist(), tokenizer, tokenizer_max_len, truncate)\n",
    "    valid_dataset = Dataset(val.input.tolist(), val.iloc[:, 3:].values.tolist(), tokenizer, tokenizer_max_len, truncate)\n",
    "    \n",
    "    return train_dataset, valid_dataset\n",
    "\n",
    "def build_dataloader(train_dataset, valid_dataset, batch_size):\n",
    "    '''\n",
    "    Create the torch dataloaders\n",
    "    '''\n",
    "    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    valid_data_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "    return train_data_loader, valid_data_loader\n",
    "\n",
    "def get_classWeigths():\n",
    "    \n",
    "    train_labels = train.iloc[:, 3:]\n",
    "    tot = sum(train_labels.sum(axis=0))\n",
    "    weight = 1 - (train_labels.sum(axis=0) / tot)\n",
    "    \n",
    "    return torch.tensor(weight)\n",
    "\n",
    "def ret_model(n_train_steps, do_prob):\n",
    "    '''\n",
    "    Retrieve the model\n",
    "    '''\n",
    "    model = Classifier(n_train_steps, n_labels, do_prob, bert_model=bert_model)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ret_optimizer(model):\n",
    "    '''\n",
    "    Taken from Abhishek Thakur's Tez library example: \n",
    "    https://github.com/abhishekkrthakur/tez/blob/main/examples/text_classification/binary.py\n",
    "    '''\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\"]\n",
    "    optimizer_parameters = [\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": 0.001,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "#     opt = AdamW(optimizer_parameters, lr=config['learning_rate'])\n",
    "    opt = torch.optim.AdamW(optimizer_parameters, lr=config['learning_rate'])\n",
    "    return opt\n",
    "\n",
    "def ret_scheduler(optimizer, num_train_steps):\n",
    "    sch = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=0, num_training_steps=num_train_steps)\n",
    "    return sch\n",
    "\n",
    "def loss_function(outputs, labels, weights, loss='BCE'):\n",
    "    if labels is None:\n",
    "        return None\n",
    "    if loss == 'BCE':\n",
    "        # BinaryCross Entropy loss\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        return loss_fn(outputs, labels.float())\n",
    "    elif loss == 'SigF1':\n",
    "#         S=-1\n",
    "#         E=0\n",
    "#         y_hat = torch.sigmoid(outputs)\n",
    "#         y = labels\n",
    "#         # Sigmoid hyperparams:\n",
    "#         b = torch.tensor(S)\n",
    "#         c = torch.tensor(E)\n",
    "\n",
    "#         # Calculate the sigmoid\n",
    "#         sig = 1 / (1 + torch.exp(b * (y_hat + c)))\n",
    "        sig = outputs\n",
    "        tp = torch.sum(sig * y, dim=0)\n",
    "        fp = torch.sum(sig * (1 - y), dim=0)\n",
    "        fn = torch.sum((1 - sig) * y, dim=0)\n",
    "\n",
    "        sigmoid_f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "        cost = 1 - sigmoid_f1\n",
    "        macroCost = torch.mean(cost)\n",
    "\n",
    "        return macroCost\n",
    "    \n",
    "    elif loss == 'SigF1_weighted':\n",
    "        # Sigmoid hyperparams:\n",
    "        b = torch.tensor(S)\n",
    "        c = torch.tensor(E)\n",
    "\n",
    "        # Calculate the sigmoid\n",
    "        sig = 1 / (1 + torch.exp(b * (y_hat + c)))\n",
    "        tp = torch.sum(sig * y, dim=0)\n",
    "        fp = torch.sum(sig * (1 - y), dim=0)\n",
    "        fn = torch.sum((1 - sig) * y, dim=0)\n",
    "\n",
    "        sigmoid_f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n",
    "\n",
    "        cost = 1 - sigmoid_f1\n",
    "        weighted_cost = cost * weights\n",
    "        macroCost = torch.mean(weighted_cost)\n",
    "        \n",
    "    else:\n",
    "        # BinaryCross Entropy loss\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "        return loss_fn(outputs, labels.float())\n",
    "\n",
    "def log_metrics(preds, labels):\n",
    "    preds = torch.stack(preds)\n",
    "    preds = preds.cpu().detach().numpy()\n",
    "    labels = torch.stack(labels)\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "    \n",
    "    '''\n",
    "    auc_micro_list = []\n",
    "    for i in range(n_labels):\n",
    "      current_pred = preds.T[i]\n",
    "      current_label = labels.T[i]\n",
    "      fpr_micro, tpr_micro, _ = metrics.roc_curve(current_label.T, current_pred.T)\n",
    "      auc_micro = metrics.auc(fpr_micro, tpr_micro)\n",
    "      auc_micro_list.append(auc_micro)\n",
    "    \n",
    "    return {\"auc\": np.array(auc_micro).mean()}\n",
    "    '''\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html#sklearn.metrics.roc_curve\n",
    "    fpr_micro, tpr_micro, _ = metrics.roc_curve(labels.ravel(), preds.ravel())\n",
    "    \n",
    "    auc_micro = metrics.auc(fpr_micro, tpr_micro)\n",
    "    return {\"auc_micro\": auc_micro}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the training and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train_fn(data_loader, model, loss_fn, optimizer, device, scheduler, weights):\n",
    "    '''\n",
    "        Modified from Abhishek Thakur's BERT example: \n",
    "        https://github.com/abhishekkrthakur/bert-sentiment/blob/master/src/engine.py\n",
    "        \n",
    "        Gradient scaling:\n",
    "        https://pytorch.org/docs/stable/amp.html#gradient-scaling\n",
    "    '''\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        ids = d[\"ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        targets = d[\"labels\"]\n",
    "\n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(ids=ids, mask=mask)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            loss = loss_function(outputs, targets, weights, loss_fn)\n",
    "#         loss.backward()\n",
    "        scaler.scale(loss).backward()\n",
    "        train_loss += loss.item()\n",
    "#         optimizer.step()\n",
    "        scaler.step(optimizer)\n",
    "#         scheduler.step()\n",
    "        scaler.update()\n",
    "\n",
    "    return train_loss\n",
    "    \n",
    "\n",
    "def eval_fn(data_loader, model, loss_fn, weights, device):\n",
    "    '''\n",
    "        Modified from Abhishek Thakur's BERT example: \n",
    "        https://github.com/abhishekkrthakur/bert-sentiment/blob/master/src/engine.py\n",
    "    '''\n",
    "    eval_loss = 0.0\n",
    "    model.eval()\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            ids = d[\"ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            targets = d[\"labels\"]\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(ids=ids, mask=mask)\n",
    "            loss = loss_function(outputs, targets, weights, loss_fn)\n",
    "            eval_loss += loss.item()\n",
    "            fin_targets.extend(targets)\n",
    "            fin_outputs.extend(torch.sigmoid(outputs))\n",
    "    return eval_loss, fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(config):\n",
    "\n",
    "    train_dataset, valid_dataset = build_dataset(config['tokenizer_max_len'], config['truncate'])\n",
    "    train_data_loader, valid_data_loader = build_dataloader(train_dataset, valid_dataset, config['batch_size'])\n",
    "    print(\"Length of Train Dataloader: \", len(train_data_loader))\n",
    "    print(\"Length of Valid Dataloader: \", len(valid_data_loader))\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    weights = get_classWeigths()\n",
    "\n",
    "    n_train_steps = int(len(train_dataset) / config['batch_size'] * 10)\n",
    "\n",
    "    model = ret_model(n_train_steps, config['dropout'])\n",
    "    optimizer = ret_optimizer(model)\n",
    "    scheduler = ret_scheduler(optimizer, n_train_steps)\n",
    "    model.to(device)\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "    n_epochs = config['epochs']\n",
    "    loss_fn = config['loss']\n",
    "    \n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "\n",
    "    best_val_loss = 100\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        print('Train EPOCH: ', epoch+1)\n",
    "        train_loss = train_fn(train_data_loader, model, loss_fn, optimizer, device, scheduler, weights)\n",
    "        eval_loss, preds, labels = eval_fn(valid_data_loader, model, loss_fn, weights, device)\n",
    "        \n",
    "        metrics_eval = log_metrics(preds, labels)\n",
    "        try:\n",
    "            auc_score  = metrics_eval[\"auc_micro\"]\n",
    "#             print(\"AUC score: \", auc_score)\n",
    "        except:\n",
    "            pass\n",
    "        avg_train_loss, avg_val_loss = train_loss / len(train_data_loader), eval_loss / len(valid_data_loader)\n",
    "        \n",
    "        train_losses.append(avg_train_loss)\n",
    "        eval_losses.append(avg_val_loss)\n",
    "        \n",
    "        print(\"Average Train loss: \", avg_train_loss)\n",
    "        print(\"Average Valid loss: \", avg_val_loss)\n",
    "        torch.save(model.state_dict(), \"./models/model_current_freeze_512_2laySM.pt\")  \n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), \"./models/model_best_freeze_512_2laySM_\"+ str(epoch+1) +\".pt\")  \n",
    "            print(\"Model saved as current val_loss is: \", best_val_loss) \n",
    "            \n",
    "    return train_losses, eval_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set some configuration parameters (to be fine-tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'learning_rate': 1e-5,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 10,\n",
    "    'dropout': 0.5,\n",
    "    'tokenizer_max_len': 512,\n",
    "    'truncate': True,\n",
    "#     'loss': 'BCE',\n",
    "    'loss': 'SigF1',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Train Dataloader:  9486\n",
      "Length of Valid Dataloader:  1583\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a279e1433d8340c3a0b3dee992decb8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train EPOCH:  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee6c03bf260436b950456cf365c05ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94/4219592962.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = F.softmax(self.out2(output_3))\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d16a29751cd4b13b93db17762ce952f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1583 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train loss:  0.6893645346466308\n",
      "Average Valid loss:  0.6893883424323342\n",
      "Model saved as current val_loss is:  0.6893883424323342\n",
      "Train EPOCH:  3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef54777bfb446f9b7af8547ce81e8ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94/4219592962.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = F.softmax(self.out2(output_3))\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7471252dc291404bb9d540b2f4db5fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1583 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce87eac103b4ffc945ec9f746b8c4d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1583 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train loss:  0.6882661926502571\n",
      "Average Valid loss:  0.6877116723596786\n",
      "Model saved as current val_loss is:  0.6877116723596786\n",
      "Train EPOCH:  6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20dd484983424f12be5b3fab92274157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94/4219592962.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = F.softmax(self.out2(output_3))\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c76a64e25847e6a12e6aaa88d0d446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1583 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78f943a328945d1bcc530363f642478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1583 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train loss:  0.6878622996890039\n",
      "Average Valid loss:  0.6874271035194397\n",
      "Model saved as current val_loss is:  0.6874271035194397\n"
     ]
    }
   ],
   "source": [
    "# Train the model:\n",
    "\n",
    "train_loss, eval_loss = trainer(config)\n",
    "\n",
    "# Save the losses\n",
    "loss_epochs = pd.DataFrame([train_loss, eval_loss]).rename(index={0: \"Train loss\", 1: \"Eval loss\"}).T\n",
    "loss_epochs.to_csv('outputs/loss_epochs_sci512_2layDrop_freeze_F1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train loss</th>\n",
       "      <th>Eval loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train loss  Eval loss\n",
       "0    0.000073   0.000435\n",
       "1    0.000073   0.000435\n",
       "2    0.000073   0.000435\n",
       "3    0.000073   0.000435\n",
       "4    0.000073   0.000434\n",
       "5    0.000073   0.000434\n",
       "6    0.000073   0.000434\n",
       "7    0.000073   0.000434\n",
       "8    0.000073   0.000434\n",
       "9    0.000073   0.000434"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_epochs\n",
    "# loss_epochs.plot( kind = 'line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAD4CAYAAAA+epuFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAArsElEQVR4nO3de3hV9Z3v8fc3OzcSwtVwCRcTCIogBJyUeiugeBSLgHOqpzi1Y3s8w2ChTsfTp+o5PU8vp53xNtpaUcdqW2ccRY7tdEKp0nZQ1NoqQUEIiCQEJdwMAQMBQm7f88dewDbmsgMJayf5vJ4nD2v91m/91ndtYH+yLnttc3dERES6QlLYBYiISM+lkBERkS6jkBERkS6jkBERkS6jkBERkS6THHYBieacc87x3NzcsMsQEelW1q1bt9/ds5u3K2Sayc3Npbi4OOwyRES6FTP7oKV2nS4TEZEuo5AREZEuo5AREZEuo2syItLr1NfXU1FRQW1tbdildDvp6emMHDmSlJSUuPorZESk16moqCArK4vc3FzMLOxyug13p6qqioqKCvLy8uJaR6fLRKTXqa2tZfDgwQqYDjIzBg8e3KEjQIWMiPRKCpjT09HXTafLOskv/ljOgSN1rXdo5S+mrb+utv4urY01E+H/TmpyEl+++Fwy0/RPTKQ30ztAJ3n2rQ/Z9lFNi8t661f21NY38o2rzgu7DJGEFIlEmDRp0sn5BQsWcNddd3V4nJkzZ/LAAw9QWFgYV/vZppDpJL/7+xmdOl5bXybXVmglSp4temYdP//jDv7H58bQV0czIp/Sp08f1q9fH3YZXU7XZBKUmbX6k5TU+k8kQX6+NnMs1cfqee7ND8N+KUW6jZdeeokbb7zx5Pwrr7zCddddB8Btt91GYWEhEydO5Dvf+U6Hxn3uueeYNGkSF154IXfeeScAjY2NfOUrX+HCCy9k0qRJPPTQQwA8/PDDTJgwgcmTJ7NgwYIz3if9iildYurogVyWP5ifvradL19yLukpkbBLEmnR91aUsHn3oU4dc0JOP74zd2KbfY4dO8aUKVNOzt9999184QtfYOHChRw5coTMzEyef/75k2/0P/zhDxk0aBCNjY3MmjWLd999l8mTJ7dby+7du7nzzjtZt24dAwcO5Oqrr+bXv/41o0aNYteuXWzatAmAjz/+GIB77rmH8vJy0tLSTradCR3JSJdZPDOfjw4f55dvV4RdikjCOXG67MTPF7/4RZKTk5k9ezYrVqygoaGBlStXMn/+fACWL1/ORRddxNSpUykpKWHz5s1xbWft2rXMnDmT7OxskpOT+dKXvsSrr77KmDFj2L59O1//+td56aWX6NevHwCTJ0/mS1/6Es888wzJyWd+HKIjGekyl4wdzJRRA3h8TRlfLBxFckS/00jiae+I42xbsGABjzzyCIMGDaKwsJCsrCzKy8t54IEHWLt2LQMHDuQrX/nKGT+tYODAgWzYsIFVq1bx+OOPs3z5cn72s5+xcuVKXn31VVasWMEPf/hDNm7ceEZho//10mXMjMVX5LPzwDF+8+6esMsR6RZmzJjB22+/zU9/+tOTp8oOHTpEZmYm/fv3Z9++fbz44otxjzdt2jTWrFnD/v37aWxs5LnnnmPGjBns37+fpqYmvvCFL/CDH/yAt99+m6amJnbu3MkVV1zBvffeS3V1NTU1Ld81Gy8dyUiXmjV+COcPzeLRV0qZV5BDUlICfIhHJAE0vyYze/Zs7rnnHiKRCNdddx2/+MUvePrppwEoKChg6tSpjB8/nlGjRnHZZZfFvZ3hw4dzzz33cMUVV+DuzJkzh/nz57Nhwwa++tWv0tTUBMA//uM/0tjYyM0330x1dTXuzu23386AAQPOaD+trVtle6PCwkLXl5Z1rv9Yv4u/W7aeJ778F1w9cVjY5YiwZcsWLrjggrDL6LZaev3MbJ27f+pDOTpdJl1uzqThjB6UwdJXytr8/I+I9DwKGelyyZEkFs0Yy4adH/NGWVXY5YjIWaSQkbPiC38xgiFZaSx9uTTsUkSAtp+qIa3r6OsWV8iY2Wwz22pmpWb2qYfrmFmamT0fLH/TzHJjlt0dtG81s2s6MObDZlYTM7/IzDaa2Xoze93MJgTtuWZ2LGhfb2aPtzBWkZltimdfpWukJUdYOH0Mb5RV8faHB8MuR3q59PR0qqqqFDQddOL7ZNLT0+Nep927y8wsAiwF/gtQAaw1syJ3j/0k0K3AQXfPN7MFwL3AF4MgWABMBHKAP5jZiScmtjqmmRUCA5uV8qy7Px4snwc8CMwOlpW5+5RW6v+vwJndgyed4qZpo3nk5VIefbmMJ28J96F90ruNHDmSiooKKisrwy6l2znxzZjxiucW5mlAqbtvBzCzZcB8IDZk5gPfDaZfAB6x6JcOzAeWuftxoNzMSoPxaG3MINTuB/4K+MsTG3D32Oc+ZBLHsyDNrC9wB7AQWB7HvkoXykxL5quX5vHQH97nvb2HGD+sX9glSS+VkpIS9zc7ypmJ53TZCGBnzHxF0NZiH3dvAKqBwW2s29aYS4Aid//Up/fMbLGZlQH3AbfHLMozs3fMbI2ZfS6m/f8C/wQcbWsHzWyhmRWbWbF+s+lat1x6LpmpER57pSzsUkTkLEioC/9mlgPcCPykpeXuvtTdxwJ3At8OmvcAo919KtGjlmfNrJ+ZTQHGuvu/t7ddd3/C3QvdvTA7O7szdkVaMSAjlZsvPpcVG3bzQdWRsMsRkS4WT8jsAkbFzI8M2lrsY2bJQH+gqo11W2ufCuQDpWa2A8gITrE1twy4HsDdj7t7VTC9DigDzgMuAQqDcV4HzjOzV+LYX+lit16eR3IkicfXbA+7FBHpYvGEzFpgnJnlmVkq0Qv5Rc36FAG3BNM3AKs9ettGEbAguPssDxgHvNXamO6+0t2HuXuuu+cCR909H8DMxsVsbw6wLWjPDq7jYGZjgm1sd/fH3D0nGOdy4H13nxn/SyNdZUi/dP5b4Uh+ua6CvdVn9pA/EUls7YZMcI1lCbAK2AIsd/cSM/t+cJcXwFPA4OCo4w7grmDdEqIX3DcDLwGL3b2xtTHbKWWJmZWY2fpgGydCbTrwbtD+ArDI3Q/EtfcSmr+dPpZGd558TUczIj2Znl3WjJ5ddvbc8fx6Xty0lzfuupKBmalhlyMiZ0DPLpOEc9vMsRyrb+TnfywPuxQR6SIKGQnNuKFZXDNxKL94YweHa+vDLkdEuoBCRkL1tZn5HKpt4N/e/DDsUkSkCyhkJFQFowbwuXHn8ORr5dTWN4Zdjoh0MoWMhO5rM/PZX3Oc/1e8s/3OItKtKGQkdBePGcRFowfw+Jrt1Dc2hV2OiHQihYyEzsxYfEU+uz4+RtH63WGXIyKdSCEjCeHK8UMYPyyLR18ppalJn90S6SkUMpIQzIyvXZFPWeURfrd5b9jliEgnUchIwpgzaTi5gzNY+nKZvrFQpIdQyEjCiCQZi2aMZeOual7btj/sckSkEyhkJKH85UUjGNYvnaUvt/QNDyLS3ShkJKGkJUf4m+ljeLP8AMU79DBtke5OISMJ56ZpoxiYkcKj+opmkW5PISMJJyM1mf9+WR6r3/uIkt3VYZcjImdAISMJ6a8vyaVvWjKP6WhGpFtTyEhC6p+Rws0Xn8vKjXvYXlkTdjkicpoUMpKwbr08j9RIEv+8Rl/RLNJdKWQkYWVnpfHFz4ziV+9UsPvjY2GXIyKnQSEjCW3h9DG4w09f09GMSHekkJGENnJgBvOnjOC5tz6kquZ42OWISAcpZCTh3TZzDMcbmvj5H3eEXYqIdJBCRhJe/pAsZk8cxtN/2sGh2vqwyxGRDogrZMxstpltNbNSM7urheVpZvZ8sPxNM8uNWXZ30L7VzK7pwJgPm1lNzPwiM9toZuvN7HUzmxC055rZsaB9vZk9HrRnmNlKM3vPzErM7J4OvTKSUL42M5/DtQ088+cPwi5FRDqg3ZAxswiwFLgWmADcdOINPsatwEF3zwceAu4N1p0ALAAmArOBR80s0t6YZlYIDGy2jWfdfZK7TwHuAx6MWVbm7lOCn0Ux7Q+4+3hgKnCZmV3b3v5KYpo0sj/Tz8vmqdfKOVbXGHY5IhKneI5kpgGl7r7d3euAZcD8Zn3mA08H0y8As8zMgvZl7n7c3cuB0mC8VscMAuh+4FuxG3D3QzGzmUCbXzji7kfd/eVgug54GxgZx/5Kglo8cyxVR+pYXrwz7FJEJE7xhMwIIPZ/dUXQ1mIfd28AqoHBbazb1phLgCJ339O8EDNbbGZlRI9kbo9ZlGdm75jZGjP7XAvrDQDmAv/Z0g6a2UIzKzaz4srKypa6SAKYljeIwnMH8s9ryqhraAq7HBGJQ0Jd+DezHOBG4CctLXf3pe4+FrgT+HbQvAcY7e5TgTuAZ82sX8yYycBzwMPu3uKHLdz9CXcvdPfC7Ozsztsh6VRmxuIr8tldXct/rN8VdjkiEod4QmYXMCpmfmTQ1mKf4E29P1DVxrqttU8F8oFSM9sBZJhZS99etQy4HiA4FVcVTK8DyoDzYvo+AWxz9x/Fsa+S4Gaen80Fw/vx2JoyGpv0Fc0iiS6ekFkLjDOzPDNLJXohv6hZnyLglmD6BmC1R7+kvQhYENx9lgeMA95qbUx3X+nuw9w9191zgaPBzQSY2biY7c0BtgXt2cF1HMxsTLCN7cH8D4gG3jfifkUkoUWPZsayvfIIq0r2hl2OiLQjub0O7t5gZkuAVUAE+Jm7l5jZ94Fidy8CngL+NTjqOEA0NAj6LQc2Aw3AYndvBGhpzHZKWWJmVwH1wEFOhdp04PtmVg80AYvc/YCZjQT+N/Ae8Hb0PgQecfcn43plJGFde+Fw8s55n6Uvl3LthcMI/m5FJAFZ9IBDTigsLPTi4uKwy5B2LF+7k2/98l1+8dXPMPP8IWGXI9Lrmdk6dy9s3p5QF/5F4nX91BEM75/Ooy/rS81EEplCRrql1OQkFk4fw1s7DvBW+YGwyxGRVihkpNta8JnRDMpM5dFXWroBUUQSgUJGuq0+qRFuvTyPV7ZWsmlXddjliEgLFDLSrd188blkpSXz2Cu6NiOSiBQy0q3175PCly85l99u2kNZZU37K4jIWaWQkW7vv1+eR2okicd1NCOScBQy0u2d0zeNm6aN5t/f2cWuj4+FXY6IxFDISI/wN9PHAPDTV1t8BqqIhEQhIz3CiAF9+MupI3jurQ/ZX3M87HJEJKCQkR5j0cyx1DU28bPXy8MuRUQCChnpMcZm9+XzFw7nX//0AdXH6sMuR0RQyEgPc9vMsRw+3sAzf/4g7FJEBIWM9DAXjujPzPOzeer1co7VNYZdjkivp5CRHmfxFfkcOFLHsrUfhl2KSK+nkJEe5zO5g5iWO4gnXt1OXUNT2OWI9GoKGemRvnbFWPZU1/Lrd3aFXYpIr6aQkR5pxnnZTMzpx2Nrymhs0re/ioRFISM9kpnxtzPGUr7/CH/eXhV2OSK9lkJGeqyrJwwlMzVC0frdYZci0mspZKTHSk+JcPXEYby4aY9uABAJiUJGerS5BcM5VNvAa9sqwy5FpFdSyEiPdnl+NgMyUijaoFNmImGIK2TMbLaZbTWzUjO7q4XlaWb2fLD8TTPLjVl2d9C+1cyu6cCYD5tZTcz8IjPbaGbrzex1M5sQtOea2bGgfb2ZPR6zzl8E65QG41ncr4z0CKnJSVx74TB+v3mfngAgEoJ2Q8bMIsBS4FpgAnDTiTf4GLcCB909H3gIuDdYdwKwAJgIzAYeNbNIe2OaWSEwsNk2nnX3Se4+BbgPeDBmWZm7Twl+FsW0Pwb8DTAu+Jnd3v5KzzN3cg5H6xpZ/d5HYZci0uvEcyQzDSh19+3uXgcsA+Y36zMfeDqYfgGYFRw1zAeWuftxdy8HSoPxWh0zCKD7gW/FbsDdD8XMZgJtfvjBzIYD/dz9z+7uwL8A18exv9LDfHbMYLKz0lihU2YiZ108ITMC2BkzXxG0tdjH3RuAamBwG+u2NeYSoMjd9zQvxMwWm1kZ0SOZ22MW5ZnZO2a2xsw+F1NTRTt1nxh3oZkVm1lxZaUuEPc0kSRjzqThrN76EYdq9RUAImdTQl34N7Mc4EbgJy0td/el7j4WuBP4dtC8Bxjt7lOBO4BnzaxfR7br7k+4e6G7F2ZnZ5/+DkjCmluQQ11DE78v2Rd2KSK9SjwhswsYFTM/MmhrsY+ZJQP9gao21m2tfSqQD5Sa2Q4gw8xKW6hpGcGpr+BUXFUwvQ4oA84LxhvZTt3SS1w0egAjBvRhxbs6ZSZyNsUTMmuBcWaWZ2apRC/kFzXrUwTcEkzfAKwOroMUAQuCu8/yiF58f6u1Md19pbsPc/dcd88FjgY3E2Bm42K2NwfYFrRnB9dxMLMxwTa2B6fbDpnZxcH1ob8G/qMDr430IGbG3IIcXt+2nwNH6sIuR6TXaDdkgmssS4BVwBZgubuXmNn3zWxe0O0pYHBw1HEHcFewbgmwHNgMvAQsdvfG1sZsp5QlZlZiZuuDbZwItenAu0H7C8Aidz8QLPsa8CTRGw7KgBfb21/pueYWDKehyXlx06cu94lIF7HoAYecUFhY6MXFxWGXIV3A3bnqwTVkZ6WxbOElYZcj0qOY2Tp3L2zenlAX/kW60olTZm+WH2BvdW3Y5Yj0CgoZ6VXmFuTgDis36pSZyNmgkJFeZWx2Xybm9NMHM0XOEoWM9DpzC3JYv/NjPqw6GnYpIj2eQkZ6nTmThgPoMzMiZ4FCRnqdUYMyuGj0AJ0yEzkLFDLSK80ryOG9vYfZtu9w2KWI9GgKGemVPj95OEmGjmZEuphCRnqlIVnpXDxmMCve3YM+kCzSdRQy0mvNK8ihfP8RNu061H5nETktChnptWZfOIzkJNNdZiJdSCEjvdaAjFSmn5fNbzbspqlJp8xEuoJCRnq1eQU57K6u5e0PD4ZdikiPpJCRXu2qCUNJS06iSHeZiXQJhYz0an3Tkpl1wRB+u3EPDY1NYZcj0uMoZKTXm1eQw/6aOv68/UD7nUWkQxQy0uvNPH8IfdOSKdqwK+xSRHochYz0eukpEa6eMJSXNu3leENj2OWI9CgKGRFg7pQcDtU28Nr7+8MuRaRHUciIAJfnn8OAjBTdZSbSyRQyIkBKJIlrLxzO7zfv42hdQ9jliPQYChmRwLyCHI7VN7L6vY/CLkWkx1DIiASm5Q1iSFYaRet1ykyks8QVMmY228y2mlmpmd3VwvI0M3s+WP6mmeXGLLs7aN9qZtd0YMyHzawmZn6RmW00s/Vm9rqZTWjWf7SZ1ZjZN2Pa/t7MSsxsk5k9Z2bp8eyv9E6RJGPO5OG8srWSQ7X1YZcj0iO0GzJmFgGWAtcCE4Cbmr/BA7cCB909H3gIuDdYdwKwAJgIzAYeNbNIe2OaWSEwsNk2nnX3Se4+BbgPeLDZ8geBF2PGGAHcDhS6+4VAJKhFpFXzCnKoa2zidyX7wi5FpEeI50hmGlDq7tvdvQ5YBsxv1mc+8HQw/QIwy8wsaF/m7sfdvRwoDcZrdcwggO4HvhW7AXeP/dKPTODkY3PN7HqgHChpVlcy0MfMkoEMQOdBpE1TRg1g5MA+ustMpJPEEzIjgJ0x8xVBW4t93L0BqAYGt7FuW2MuAYrcfU/zQsxssZmVET2SuT1o6wvcCXwvtq+77wIeAD4E9gDV7v67lnbQzBaaWbGZFVdWVrbURXoJM2NuQQ5/LN1PVc3xsMsR6fYS6sK/meUANwI/aWm5uy9197FEQ+XbQfN3gYfcvSa2r5kNJHp0lAfkAJlmdnMr4z7h7oXuXpidnd0p+yLd17yCHBqbnBc37Q27FJFuLzmOPruAUTHzI4O2lvpUBKem+gNV7azbUvtUIB8ojZ5tI8PMSoNrPbGWAY8F058FbjCz+4ABQJOZ1QL7gHJ3rwQws18BlwLPxLHP0ouNH5ZF/pC+FG3Yzc0Xnxt2OSLdWjxHMmuBcWaWZ2apRC+eFzXrUwTcEkzfAKx2dw/aFwR3n+UB44C3WhvT3Ve6+zB3z3X3XODoiYAxs3Ex25sDbANw98/F9P8R8A/u/gjR02QXm1lGcH1oFrAl/pdGeiszY+7kHNbuOMCe6mNhlyPSrbUbMsE1liXAKqJv0svdvcTMvm9m84JuTwGDzawUuAO4K1i3BFgObAZeAha7e2NrY7ZTypLgduT1wTZuaauzu79J9CaEt4GNwb4+0d7+igDMLRiOO6x891OXBkWkAyx6wCEnFBYWenFxcdhlSAK47ievETHjP5ZcHnYpIgnPzNa5e2Hz9oS68C+SSOZOzmFDRTUfVB0JuxSRbkshI9KK6wpyAPiNTpmJnDaFjEgrRgzoQ+G5A1mhD2aKnDaFjEgb5hbk8N7ew7y/73DYpYh0SwoZkTZ8ftJwkgwdzYicJoWMSBuys9K4dOw5rNiwG92JKdJxChmRdswtGM6OqqNs3FUddiki3Y5CRqQdsycOJyViOmUmchoUMiLt6J+RwozzsvnNu3toatIpM5GOUMiIxGFuQQ57qmsp/uBg2KWIdCsKGZE4XHXBUNJTknTKTKSDFDIicchMS2bWBUP57cY9NDQ2hV2OSLehkBGJ09zJOVQdqeONsqqwSxHpNhQyInGaeX42WWnJOmUm0gEKGZE4padEuHriMF4q2cvxhsawyxHpFhQyIh0wt2A4h2sbWLO1MuxSRLoFhYxIB1yWfw4DM1JYocf/i8RFISPSASmRJD4/aTh/2LyPo3UNYZcjkvAUMiIdNLcgh2P1jfxhy0dhlyKS8BQyIh30mdxBDO2XprvMROKgkBHpoEiScd3kHNZsraT6WH3Y5YgkNIWMyGmYW5BDXWMTq0r2hl2KSEJTyIichoKR/Rk9KEOnzETaEVfImNlsM9tqZqVmdlcLy9PM7Plg+Ztmlhuz7O6gfauZXdOBMR82s5qY+UVmttHM1pvZ62Y2oVn/0WZWY2bfjGkbYGYvmNl7ZrbFzC6JZ39F2mNmzC0YzhtlVeyvOR52OSIJq92QMbMIsBS4FpgA3NT8DR64FTjo7vnAQ8C9wboTgAXARGA28KiZRdob08wKgYHNtvGsu09y9ynAfcCDzZY/CLzYrO3HwEvuPh4oALa0t78i8ZpbkENjk/PiJp0yE2lNPEcy04BSd9/u7nXAMmB+sz7zgaeD6ReAWWZmQfsydz/u7uVAaTBeq2MGAXQ/8K3YDbj7oZjZTODkt0eZ2fVAOVAS09YfmA48Faxf5+4fx7G/InE5f2gW44b0ZcV6nTITaU08ITMC2BkzXxG0tdjH3RuAamBwG+u2NeYSoMjdP/WRajNbbGZlRI9kbg/a+gJ3At9r1j0PqAR+bmbvmNmTZpbZ0g6a2UIzKzaz4spKPS5E4mNmzCvI4a0dB9hTfSzsckQSUkJd+DezHOBG4CctLXf3pe4+lmiofDto/i7wkLvXNOueDFwEPObuU4EjwKeu/QTjPuHuhe5emJ2dfeY7Ir3GdQU5AKzUY2ZEWhRPyOwCRsXMjwzaWuxjZslAf6CqjXVba58K5AOlZrYDyDCz0hZqWgZcH0x/Frgv6P8N4H+Z2RKiR0cV7v5m0O8FoqEj0mnyzslk0oj+FOkuM5EWxRMya4FxZpZnZqlEL+QXNetTBNwSTN8ArHZ3D9oXBHef5QHjgLdaG9PdV7r7MHfPdfdc4GhwMwFmNi5me3OAbQDu/rmY/j8C/sHdH3H3vcBOMzs/WGcWsDnO10UkbvMKcni3opod+4+EXYpIwmk3ZIJrLEuAVUTvzlru7iVm9n0zmxd0ewoYHBx13EFwWsrdS4DlRN/cXwIWu3tja2O2U8oSMysxs/XBNm5ppz/A14F/M7N3gSnAP8SxjkiHzJk8HIDfvKujGZHmLHrAIScUFhZ6cXFx2GVIN3Pj429Qfaye3/39jLBLEQmFma1z98Lm7Ql14V+ku5pXkMP7+2rYuvdw2KWIJBSFjEgnuHbScJIMPWZGpBmFjEgnOKdvGpfln0PRht3oFLTIKQoZkU4ytyCHDw8c5d2K6rBLEUkYChmRTnLNxGGkREynzERiKGREOkn/PinMOG8Iv3l3D01NOmUmAgoZkU41b0oOew/VsnbHgbBLEUkIChmRTnTVBUPokxJhhT6YKQIoZEQ6VUZqMrMuGMJvN+6lvrEp7HJEQqeQEelk8wpyOHCkjjfKqsIuRSR0ChmRTjbj/Gyy0pN1l5kIChmRTpeWHOGaicNYtWkvtfWNYZcjEiqFjEgXmFuQw+HjDax5X9+0Kr2bQkakC1w2djCDMlN1ykx6PYWMSBdIjiTx+UnD+M8tH3G0riHsckRCo5AR6SJzJ+dwrL6R32/eF3YpIqFRyIh0kc/kDmJYv3RWbNgTdikioVHIiHSRpCTjusnDWfP+R1QfrQ+7HJFQKGREutDcghzqG51VJXvDLkUkFAoZkS40eWR/zh2cwfLinboBQHolhYxIFzIz/vqSXIo/OMjl977M0pdLOVSrU2fSeyhkRLrYrZfn8cvbLqFgZH/uX7WVy+5ZzYO/28rBI3VhlybS5UzfR/5JhYWFXlxcHHYZ0kNt2lXNI6tLealkL5mpEW6+5Fz+x+VjyM5KC7s0kTNiZuvcvbB5e1xHMmY228y2mlmpmd3VwvI0M3s+WP6mmeXGLLs7aN9qZtd0YMyHzawmZn6RmW00s/Vm9rqZTWjWf7SZ1ZjZN5u1R8zsHTP7TTz7KtKVLhzRn8e//Bes+sZ0rpowlJ++up3L713Nd4tK2FN9LOzyRDpduyFjZhFgKXAtMAG4qfkbPHArcNDd84GHgHuDdScAC4CJwGzg0eBNv80xzawQGNhsG8+6+yR3nwLcBzzYbPmDwIst7MLfAVva20+Rs+n8YVn8eMFU/nDHDOYV5PDMnz9g+n0vc/evNvJh1dGwyxPpNPEcyUwDSt19u7vXAcuA+c36zAeeDqZfAGaZmQXty9z9uLuXA6XBeK2OGQTQ/cC3Yjfg7odiZjOBk+f5zOx6oBwoiV3HzEYCc4An49hPkbNuTHZf7r+xgJe/OZMvfmYUv1xXwRX/9Ap3LF9PWWVN+wOIJLh4QmYEsDNmviJoa7GPuzcA1cDgNtZta8wlQJG7f+pj0ma22MzKiB7J3B609QXuBL7XQu0/IhpWbX5FoZktNLNiMyuurNRTc+XsGzUogx9cP4nX7ryCr1yay2837uGqB9ew5Nm32bLnUPsDiCSohLq7zMxygBuBn7S03N2XuvtYoqHy7aD5u8BD7v6JX/vM7DrgI3df19523f0Jdy9098Ls7Owz2QWRMzK0Xzr/57oJvH7nldw2YyyvbK3k2h+/xt/8SzEbdn4cdnkiHZYcR59dwKiY+ZFBW0t9KswsGegPVLWzbkvtU4F8oDR6to0MMysNrvXEWgY8Fkx/FrjBzO4DBgBNZlZL9Mhonpl9HkgH+pnZM+5+cxz7LBKqc/qm8a3Z4/nb6WP5+Rvl/PyPO5i/+Y9MPy+b26/MpzB3UNglisSl3VuYg9B4H5hFNAjWAn/l7iUxfRYDk9x9kZktAP6ru/83M5sIPEv0GkwO8J/AOMDaGzMYt8bd+wbT49x9WzA9F/hO89vlzOy7QI27P9CsfSbwTXe/rr0XRLcwSyI6XFvPM3/+kCdf207VkTouHjOIr185jkvHDib4hUwkVK3dwtzukYy7N5jZEmAVEAF+5u4lZvZ9oNjdi4CngH81s1LgANE7ygj6LQc2Aw3AYndvDAr61JjtlLLEzK4C6oGDwC3x7LhIT5CVnsJtM8fylUtzee6tD/nnV8v40pNvMnX0AL5+ZT5XnD9EYSMJSR/GbEZHMtIdHG9o5IV1FTz2ShkVB48xMacfX78yn6snDCMpSWEjZ19rRzIKmWYUMtKd1Dc28et3dvHoK2WU7z/CuCF9WXJlPnMmDSc5klD39UgPp5CJk0JGuqPGJmflxj0sXV3K1n2HyR2cwddm5nP91BGkJitspOspZOKkkJHurKnJ+f2WfTyyupSNu6oZMaAPi2aM4cbCUaSnRMIuT3owhUycFDLSE7g7a96v5CerS1n3wUGGZKWxcPoYvviZUWSlp4RdnvRACpk4KWSkJ3F3/rS9ikdWl/JGWRUA5w7OYPywLMYP6xf9c3g/Rg/KIKIbBuQMnPYtzCLSfZkZl449h0vHnsM7Hx7k9W37eW/vYbbsPcTvN++jKfgds09KhPOGZTF+aBbjh58KoIGZqeHugHR7ChmRXmLq6IFMHX3q4ea19Y1s21fDlr2HeG/PYd7be4jfb9nH88WnHis4tF9aNHCGZ3HBsH6cPyyLsdl9dTOBxE0hI9JLpadEmDSyP5NG9j/Z5u5U1hw/GTrv7T3Me3sO86eyKuoao8+ZTU4y8of0ZfywLM6PCaCh/dL0gVD5FIWMiJxkZgzJSmdIVjrTzzv1sNj6xibK9x9hy55DbN17mPf2Huat8gP8ev3uk30GZKRw/tAsLhh+6lrPeUP7kpGqt5neTH/7ItKulEgS5w3N4ryhWZ9orz5az9Z90aOeLcHRz/LinRytawTADM4dlHHylNuJGw5yBvTRKbdeQiEjIqetf0YK0/IGMS3v1FOhm5qcioPHPnGtZ+vew6zavJfYm1mz0pIZkJnCoIxUBmamMigjlQEZqQzKTGk2n8rAzBQGZqSSoqcYdDsKGRHpVElJxujBGYwenME1E4edbD9W18j7+w6zde9h9h2q5cDROg4eqePg0XoOHKmj9KMaDh6p40hwFNSSrLRkBmaeCKVo8AzMDIIoI5WBGSmfmB+QkaJgCplCRkTOij6pEQpGDaBg1IA2+x1vaOTjIHhOhlAQSAeO1PHx0ToOHK1nf00d2+IJpvTkT4dQEE6ZqREy0pLJSI0EP8nN/oxO69Te6VPIiEhCSUuOMLRfhKH90uNep7Y+GkwHT4RRs6Okg0ejAbW/po7399Vw8GjdyetG8UhOMvqkRsgMwufEdJ/m4ZQWISMlZjo1Qp+UZDKbTfc5sU5KpMc/NVshIyLdXnpKhGH9Iwzr37FgOlrXyNG6huDPYPp4I0frGzl6PNp+rL6RIyem6xo5UtfAsaD/x0fr2P3xJ8c53tDUodr7pETISk+mf58U+vVJoV96cvBnCv36JAd/fnq+f58UstKTE/50oEJGRHql9JQI6SkRBnXyUw0am5yjQRAdCcLnxPSxIIg+MX28gcO1DRyqrefQsQaqjtRRvv8Ih2obqD5WT2NT24/+ykiNtBBInw6qUyF2qi0rPbnLvxJCISMi0okiSUZWekqnPIjU3Tla13gygKJ/1p+aj52ujU5/dLiW0o9O9W0no8hMjZwMn39ffGmnf65JISMikqDMjMy0ZDLTkhnev/3+zbk7R+oaWwmmeqqbBVd6cud/HYRCRkSkhzIz+qYl0zctmRz6hFJDYl8xEhGRbk0hIyIiXUYhIyIiXUYhIyIiXSaukDGz2Wa21cxKzeyuFpanmdnzwfI3zSw3ZtndQftWM7umA2M+bGY1MfOLzGyjma03s9fNbEKz/qPNrMbMvhnMjzKzl81ss5mVmNnfxfWKiIhIp2k3ZMwsAiwFrgUmADc1f4MHbgUOuns+8BBwb7DuBGABMBGYDTxqZpH2xjSzQmDgJzfBs+4+yd2nAPcBDzZb/iDwYsx8A/A/3X0CcDGwuIW6RUSkC8VzJDMNKHX37e5eBywD5jfrMx94Oph+AZhl0a/Imw8sc/fj7l4OlAbjtTpmEED3A9+K3YC7H4qZzQROfsTIzK4HyoGSmP573P3tYPowsAUYEcf+iohIJ4knZEYAO2PmK/j0m/XJPu7eAFQDg9tYt60xlwBF7r6neSFmttjMyogeydwetPUF7gS+19oOBKfvpgJvtrJ8oZkVm1lxZWVla8OIiEgHJdSHMc0sB7gRmNnScndfCiw1s78Cvg3cAnwXeMjda1r6fvEghH4JfKPZ0VDsuE8ATwT9K83sg9PchXOA/ae5bk+k1+MUvRafpNfjlJ7yWpzbUmM8IbMLGBUzPzJoa6lPhZklA/2BqnbWbal9KpAPlAaBkWFmpcG1nljLgMeC6c8CN5jZfcAAoMnMat39ETNLIRow/+buv4pjX3H37PZ7tczMit298HTX72n0epyi1+KT9Hqc0tNfi3hCZi0wzszyiAbBAuCvmvUpInpU8SfgBmC1u7uZFQHPmtmDQA4wDngLsJbGdPcS4ORX6ZlZzYmAMbNx7r4tWDQH2Abg7p+L6f9doCYIGAOeAra4e/ObBERE5CxoN2TcvcHMlgCrgAjwM3cvMbPvA8XuXkT0zfxfzawUOEA0NAj6LQc2E73ba7G7NwK0NGY7pSwxs6uAeuAg0VBry2XAl4GNZrY+aPtf7v7b9vZZREQ6h7m38xxoiZuZLQyu7wh6PWLptfgkvR6n9PTXQiEjIiJdRo+VERGRLqOQERGRLqOQ6QTtPYetN9Ez41oWPE7pHTP7Tdi1hMnMBpjZC2b2npltMbNLwq4pTGb298H/k01m9pyZpYddU2dTyJyhOJ/t1pvomXEt+zuijzbq7X4MvOTu44ECevFrYmYjiD65pNDdLyR6p+2CcKvqfAqZMxfPs916DT0z7tPMbCTRz3Y9GXYtYTKz/sB0oh95wN3r3P3jUIsKXzLQJ/gQewawO+R6Op1C5szF82y3Xqm9Z8b1Ij8i+sDXppDrCFseUAn8PDh1+KSZZYZdVFjcfRfwAPAhsAeodvffhVtV51PISJeI55lxvYGZXQd85O7rwq4lASQDFwGPuftU4AjQa69hmtlAomc98og+ESXTzG4Ot6rOp5A5c/E8261XOZ1nxvVglwHzzGwH0VOpV5rZM+GWFJoKoMLdTxzZvkA0dHqrq4Byd69093rgV8ClIdfU6RQyZ+7ks93MLJXohbuikGsKjZ4Z90nufre7j3T3XKL/Nla7e4/7bTUe7r4X2Glm5wdNs4g+cqq3+hC42Mwygv83s+iBN0Ik1KP+u6PWnu0Wcllh0jPjpC1fB/4t+IVsO/DVkOsJjbu/aWYvAG8TvSvzHYKvHOlJ9FgZERHpMjpdJiIiXUYhIyIiXUYhIyIiXUYhIyIiXUYhIyIiXUYhIyIiXUYhIyIiXeb/A7XO8v0HSOO5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_epochs_avg = loss_epochs\n",
    "\n",
    "# train_dataset, valid_dataset = build_dataset(config['tokenizer_max_len'], config['truncate'])\n",
    "# train_data_loader, valid_data_loader = build_dataloader(train_dataset, valid_dataset, config['batch_size'])\n",
    "\n",
    "# loss_epochs_avg['Train loss'] = loss_epochs_avg['Train loss']/len(train_data_loader)\n",
    "# loss_epochs_avg['Eval loss'] = loss_epochs_avg['Eval loss']/len(valid_data_loader)\n",
    "\n",
    "loss_epochs_avg.plot(y = 'Train loss')\n",
    "loss_epochs_avg.plot(y = 'Eval loss')\n",
    "loss_epochs_avg.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some functions for the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    '''\n",
    "    Load a saved model\n",
    "    '''\n",
    "    train_dataset, valid_dataset = build_dataset(config['tokenizer_max_len'], config['truncate'])\n",
    "    train_data_loader, valid_data_loader = build_dataloader(train_dataset, valid_dataset, config['batch_size'])\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    n_train_steps = int(len(train_dataset) / config['batch_size'] * 10)\n",
    "\n",
    "    model = ret_model(n_train_steps, config['dropout'])\n",
    "    optimizer = ret_optimizer(model)\n",
    "    scheduler = ret_scheduler(optimizer, n_train_steps)\n",
    "    model.to(device)\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "    Models_PATH = \"/home/jovyan/workbench-shared-folder/canary-project/Paula_internship/models/\"\n",
    "    model.load_state_dict(torch.load(Models_PATH + model_name, map_location=device))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_batches(test, model):\n",
    "    '''\n",
    "    Predict outputs for inference phase\n",
    "    '''\n",
    "    test_targets = []\n",
    "    test_outputs = []\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    test_dataset = Dataset(test.input.tolist(), test.iloc[:, 3:].values.tolist(), tokenizer, config['tokenizer_max_len'], config['truncate'])\n",
    "    data_loader = DataLoader(test_dataset, batch_size=256, shuffle=True, num_workers=2)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            ids = d[\"ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            labels = d[\"labels\"]\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            labels = labels.to(device, dtype=torch.float)\n",
    "\n",
    "            outputs = model(ids=ids, mask=mask)\n",
    "            test_targets.extend(labels.cpu().numpy())\n",
    "            test_outputs.extend(torch.sigmoid(outputs).cpu().numpy())\n",
    "\n",
    "\n",
    "    return test_outputs, test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates():\n",
    "    '''\n",
    "    Remove duplicates of train/val datasets present in the test set\n",
    "    '''\n",
    "    # Get the training duplicates:\n",
    "    duplicates_train = set(test.pui) & set(train.pui) \n",
    "    test_clean = test[~test['pui'].isin(duplicates_train)]\n",
    "    \n",
    "    # Get the validation duplicates:\n",
    "    duplicates_val = set(test.pui) & set(val.pui) \n",
    "    test_clean = test_clean[~test_clean['pui'].isin(duplicates_val)]\n",
    "    \n",
    "    assert test_clean.shape[0] == test.shape[0] - len(duplicates_train) - len(duplicates_val)\n",
    "    \n",
    "    return test_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(preds, labels):\n",
    "    '''\n",
    "    Create some metrics: precison, recall, F1...\n",
    "    \n",
    "    A macro-average will compute the metric independently for each class and then take the average hence \n",
    "    treating all classes equally, whereas a micro-average will aggregate the contributions of all classes\n",
    "    to compute the average metric.\n",
    "    '''\n",
    "    \n",
    "    # Convert the lists to dataframes\n",
    "    lab_df = pd.DataFrame(labels)\n",
    "    pred_df = pd.DataFrame(preds).round(0).astype(int) # Threshold 0.5! \n",
    "    \n",
    "    # Calculate tp/fp/fn/tn per class:\n",
    "    tp = (pred_df + lab_df).eq(2).sum()\n",
    "    fp = (pred_df - lab_df).eq(1).sum()\n",
    "    fn = (pred_df - lab_df).eq(-1).sum()\n",
    "    tn = (pred_df + lab_df).eq(0).sum()\n",
    "    \n",
    "    # Calculate precision and recall:\n",
    "    prec = [tp[i] / (tp[i] + fp[i]) if tp[i] + fp[i] != 0 else 0.0 for i in range(len(tp))]\n",
    "    rec = [tp[i] / (tp[i] + fn[i]) if tp[i] + fn[i] != 0 else 0.0 for i in range(len(tp))]\n",
    "    \n",
    "    # Calculate F1 score:\n",
    "    f1_score = [2 * prec[i] * rec[i] / (prec[i] + rec[i]) if tp[i] > 0 else 0.0 for i in range(len(tp))]\n",
    "    \n",
    "    # Weighted F1 score:\n",
    "    weight = lab_df.sum() / sum(lab_df.sum())\n",
    "    f1_wght = [weight[i] * 2 * prec[i] * rec[i] / (prec[i] + rec[i]) if tp[i] > 0 else 0.0 for i in range(len(tp))]\n",
    "    \n",
    "    # Macro average (average over classes):\n",
    "    prec_avg = sum(prec) / len(prec)\n",
    "    rec_avg = sum(rec) / len(rec)\n",
    "    f1_avg = sum(f1_score) / len(f1_score)\n",
    "    f1wgt_avg = sum(f1_wght)\n",
    "    \n",
    "    # Micro scores (treat all samples together):\n",
    "    tp_mic = sum(tp)\n",
    "    tn_mic = sum(tn)\n",
    "    fp_mic = sum(fp)\n",
    "    fn_mic = sum(fn)\n",
    "    prec_mic = tp_mic / (tp_mic+fp_mic)\n",
    "    rec_mic = tp_mic / (tp_mic+fn_mic)\n",
    "    f1_mic = (2*prec_mic*rec_mic) / (prec_mic+rec_mic)\n",
    "    \n",
    "    return {\n",
    "        'Precision': prec, 'Recall': rec, 'F1 score': f1_score,\n",
    "        'weights': weight, 'Weighted F1 score': f1_wght,\n",
    "        'Macro precision': prec_avg.round(2), 'Macro recall': rec_avg.round(2), 'Macro F1 score': f1_avg.round(2),\n",
    "        'Weighted F1 score': f1wgt_avg.round(2),\n",
    "        'CM TP': tp, 'CM FP': fp,'CM FN': fn, 'CM TN': tn,\n",
    "        'Micro Precision': round(prec_mic, 2), 'Micro Recall': round(rec_mic, 2), 'Micro F1 score': round(f1_mic, 2),\n",
    "    }\n",
    "\n",
    "# all_metrics = get_metrics(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(preds).to_csv('outputs/Finetune/predictions.csv')\n",
    "# pd.DataFrame(labels).to_csv('outputs/Finetune/labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6d99b687b44734a95e9d6eda6c1f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/494 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_94/4219592962.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = F.softmax(self.out2(output_3))\n"
     ]
    }
   ],
   "source": [
    "# Predict outputs:\n",
    "test_clean = remove_duplicates()\n",
    "model = load_model('model_best_freeze_512_2laySM_10.pt')\n",
    "preds, labels = inference_batches(test_clean, model)\n",
    "all_metrics = get_metrics(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro precision 0.11\n",
      "Macro recall 0.06\n",
      "Macro F1 score 0.06\n",
      "Micro Precision 0.62\n",
      "Micro Recall 0.31\n",
      "Micro F1 score 0.41\n"
     ]
    }
   ],
   "source": [
    "all_metrics = get_metrics(preds, labels)\n",
    "\n",
    "for metr, val in all_metrics.items():\n",
    "    if 'Micro' in metr or 'Macro' in metr:\n",
    "        print(metr, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save outputs:\n",
    "pd.DataFrame(preds).to_csv('outputs/EXP10_TestPreds.csv')\n",
    "pd.DataFrame(preds).to_csv('outputs/Test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = pd.read_csv('outputs/EXP10_Losses.csv').drop(columns=['Unnamed: 0'])\n",
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.802107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.890188</td>\n",
       "      <td>12.519180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.608428</td>\n",
       "      <td>0.995115</td>\n",
       "      <td>0.755147</td>\n",
       "      <td>9.492444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.198261</td>\n",
       "      <td>0.002763</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>5.102014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.219462</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>0.008105</td>\n",
       "      <td>3.174493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>1.151394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.067114</td>\n",
       "      <td>0.004209</td>\n",
       "      <td>0.007922</td>\n",
       "      <td>0.881227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.020642</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.585836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.003416</td>\n",
       "      <td>0.006666</td>\n",
       "      <td>2.280284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.105386</td>\n",
       "      <td>0.007337</td>\n",
       "      <td>0.013720</td>\n",
       "      <td>0.758322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>0.004855</td>\n",
       "      <td>1.020205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.396286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.026961</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.003598</td>\n",
       "      <td>0.705649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.057214</td>\n",
       "      <td>0.003106</td>\n",
       "      <td>0.005893</td>\n",
       "      <td>0.915477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.509917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.061125</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.010014</td>\n",
       "      <td>0.566794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.119171</td>\n",
       "      <td>0.009185</td>\n",
       "      <td>0.017056</td>\n",
       "      <td>0.619220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>0.010113</td>\n",
       "      <td>0.708246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.038168</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>0.584352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.045783</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>0.007308</td>\n",
       "      <td>0.591647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.077859</td>\n",
       "      <td>0.006561</td>\n",
       "      <td>0.012103</td>\n",
       "      <td>0.603023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.009950</td>\n",
       "      <td>0.003364</td>\n",
       "      <td>0.005028</td>\n",
       "      <td>0.147015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.490291</td>\n",
       "      <td>0.203628</td>\n",
       "      <td>0.287748</td>\n",
       "      <td>8.739068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.566644</td>\n",
       "      <td>0.716922</td>\n",
       "      <td>0.632986</td>\n",
       "      <td>9.118910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.415994</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.017235</td>\n",
       "      <td>7.967145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.178431</td>\n",
       "      <td>0.003255</td>\n",
       "      <td>0.006394</td>\n",
       "      <td>3.456654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.086854</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.004958</td>\n",
       "      <td>1.792870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>0.005864</td>\n",
       "      <td>1.335997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.052342</td>\n",
       "      <td>0.002174</td>\n",
       "      <td>0.004175</td>\n",
       "      <td>1.080544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.022670</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.575326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.018041</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>0.421263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.032333</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>0.006626</td>\n",
       "      <td>0.468990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.019139</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.380583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.022277</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>0.004873</td>\n",
       "      <td>0.406796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.028061</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.006597</td>\n",
       "      <td>0.363891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.036199</td>\n",
       "      <td>0.003784</td>\n",
       "      <td>0.006852</td>\n",
       "      <td>0.522776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.040323</td>\n",
       "      <td>0.003484</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>0.532297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.300103</td>\n",
       "      <td>0.009602</td>\n",
       "      <td>0.018608</td>\n",
       "      <td>3.760206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.062868</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>1.839609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.048035</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.003877</td>\n",
       "      <td>1.346507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.041763</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>1.288023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.044917</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>1.021689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>1.464713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.056034</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.004623</td>\n",
       "      <td>1.333525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.077982</td>\n",
       "      <td>0.005759</td>\n",
       "      <td>0.010726</td>\n",
       "      <td>0.730007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.048837</td>\n",
       "      <td>0.004225</td>\n",
       "      <td>0.007776</td>\n",
       "      <td>0.614645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.020566</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>0.633192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.002971</td>\n",
       "      <td>0.005440</td>\n",
       "      <td>0.541076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.012945</td>\n",
       "      <td>0.001085</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.455760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>1.541498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.034031</td>\n",
       "      <td>0.003477</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>0.462313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.073497</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>1.701248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.035545</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.789852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Precision    Recall        F1    Weights\n",
       "0    0.802107  1.000000  0.890188  12.519180\n",
       "1    0.608428  0.995115  0.755147   9.492444\n",
       "2    0.198261  0.002763  0.005450   5.102014\n",
       "3    0.219462  0.004129  0.008105   3.174493\n",
       "4    0.036613  0.001718  0.003282   1.151394\n",
       "5    0.067114  0.004209  0.007922   0.881227\n",
       "6    0.020642  0.001900  0.003479   0.585836\n",
       "7    0.137255  0.003416  0.006666   2.280284\n",
       "8    0.105386  0.007337  0.013720   0.758322\n",
       "9    0.052632  0.002545  0.004855   1.020205\n",
       "10   0.009804  0.001248  0.002214   0.396286\n",
       "11   0.026961  0.001927  0.003598   0.705649\n",
       "12   0.057214  0.003106  0.005893   0.915477\n",
       "13   0.022222  0.002182  0.003974   0.509917\n",
       "14   0.061125  0.005454  0.010014   0.566794\n",
       "15   0.119171  0.009185  0.017056   0.619220\n",
       "16   0.076923  0.005412  0.010113   0.708246\n",
       "17   0.038168  0.003174  0.005861   0.584352\n",
       "18   0.045783  0.003971  0.007308   0.591647\n",
       "19   0.077859  0.006561  0.012103   0.603023\n",
       "20   0.009950  0.003364  0.005028   0.147015\n",
       "21   0.490291  0.203628  0.287748   8.739068\n",
       "22   0.566644  0.716922  0.632986   9.118910\n",
       "23   0.415994  0.008800  0.017235   7.967145\n",
       "24   0.178431  0.003255  0.006394   3.456654\n",
       "25   0.086854  0.002552  0.004958   1.792870\n",
       "26   0.073171  0.003054  0.005864   1.335997\n",
       "27   0.052342  0.002174  0.004175   1.080544\n",
       "28   0.022670  0.001934  0.003564   0.575326\n",
       "29   0.018041  0.002055  0.003689   0.421263\n",
       "30   0.032333  0.003691  0.006626   0.468990\n",
       "31   0.019139  0.002599  0.004577   0.380583\n",
       "32   0.022277  0.002736  0.004873   0.406796\n",
       "33   0.028061  0.003738  0.006597   0.363891\n",
       "34   0.036199  0.003784  0.006852   0.522776\n",
       "35   0.040323  0.003484  0.006414   0.532297\n",
       "36   0.300103  0.009602  0.018608   3.760206\n",
       "37   0.062868  0.002151  0.004159   1.839609\n",
       "38   0.048035  0.002020  0.003877   1.346507\n",
       "39   0.041763  0.001728  0.003319   1.288023\n",
       "40   0.044917  0.002299  0.004375   1.021689\n",
       "41   0.062500  0.002195  0.004241   1.464713\n",
       "42   0.056034  0.002411  0.004623   1.333525\n",
       "43   0.077982  0.005759  0.010726   0.730007\n",
       "44   0.048837  0.004225  0.007776   0.614645\n",
       "45   0.020566  0.001562  0.002904   0.633192\n",
       "46   0.032258  0.002971  0.005440   0.541076\n",
       "47   0.012945  0.001085  0.002003   0.455760\n",
       "48   0.030303  0.001043  0.002016   1.541498\n",
       "49   0.034031  0.003477  0.006309   0.462313\n",
       "50   0.073497  0.002398  0.004645   1.701248\n",
       "51   0.035545  0.002348  0.004405   0.789852"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics['CM TP']\n",
    "cm_df = pd.DataFrame([all_metrics['CM TP'], all_metrics['CM FP'], all_metrics['CM TN'], all_metrics['CM FN']*100]).rename(index={0: \"TP\", 1: \"FP\", 2: \"TN\", 3: \"FN\"}).T\n",
    "cm_df.to_csv('outputs/EXP10_ConfMatrix.csv')\n",
    "\n",
    "metrics_df = pd.DataFrame([all_metrics['Precision'], all_metrics['Recall'], all_metrics['F1 score'], all_metrics['weights']*100]).rename(index={0: \"Precision\", 1: \"Recall\", 2: \"F1\", 3: \"Weights\"}).T\n",
    "# metrics_df = metrics_df.rename(index={0: \"x\", 1: \"y\", 2: \"z\"})\n",
    "metrics_df.to_csv('outputs/EXP10_ClassMetrics.csv')\n",
    "metrics_df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "classify_text_with_bert.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
